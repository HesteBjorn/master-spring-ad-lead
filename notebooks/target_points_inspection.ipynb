{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import colorsys\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from lead.inference.config_open_loop import OpenLoopConfig\n",
    "from lead.inference.open_loop_inference import OpenLoopInference\n",
    "from lead.training.config_training import TrainingConfig\n",
    "\n",
    "input_root = \"outputs/local_evaluation/2397\"\n",
    "frame_index = 8\n",
    "input_path = os.path.join(input_root, f\"input_log/{frame_index:05d}.pth\")\n",
    "camera_path = os.path.join(input_root, f\"demo_images/{frame_index:05d}.png\")\n",
    "camera_calibration = {\n",
    "    \"name\": \"bev_camera\",\n",
    "    \"draw_target_points\": False,\n",
    "    \"draw_planning\": False,\n",
    "    \"image_size_x\": \"1080\",\n",
    "    \"image_size_y\": \"786\",\n",
    "    \"fov\": \"100\",\n",
    "    \"x\": 0.0,\n",
    "    \"y\": 0.0,\n",
    "    \"z\": 20.0,\n",
    "    \"pitch\": -90.0,\n",
    "    \"yaw\": 0.0,\n",
    "}\n",
    "\n",
    "camera_image = cv2.imread(camera_path)\n",
    "camera_image = cv2.cvtColor(camera_image, cv2.COLOR_BGR2RGB)\n",
    "anchors = [-20, 0, 20]\n",
    "\n",
    "num = len(anchors) ** 2\n",
    "\n",
    "rainbow_colors = []\n",
    "for k in range(num):\n",
    "    r, g, b = colorsys.hsv_to_rgb(k / num, 0.9, 0.9)\n",
    "    rgb = (np.array([r, g, b]) * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lead.common import common_utils\n",
    "\n",
    "\n",
    "def project_points_to_image(camera_rot, camera_pos, camera_fov, camera_width, camera_height, points):\n",
    "    \"\"\"\n",
    "    Project 2D points (with z=0) to image coordinates.\n",
    "\n",
    "    Returns:\n",
    "        List of ((x, y), inside_bounds) tuples\n",
    "    \"\"\"\n",
    "    camera_pos = np.array(camera_pos)\n",
    "    points_2d = np.array(points)\n",
    "\n",
    "    # Make points 3D (z=0)\n",
    "    points_3d = np.column_stack([points_2d, np.zeros(len(points_2d))])\n",
    "\n",
    "    # Get rotation matrix\n",
    "    roll, pitch, yaw = camera_rot\n",
    "    R = common_utils.euler_deg_to_mat(roll, pitch, yaw)\n",
    "\n",
    "    # Transform to camera coordinates\n",
    "    points_translated = points_3d - camera_pos\n",
    "    points_camera = (R @ points_translated.T).T\n",
    "\n",
    "    # Remap to camera coordinate system (x=right, y=down, z=forward)\n",
    "    points_cam_remapped = np.zeros_like(points_camera)\n",
    "    points_cam_remapped[:, 0] = points_camera[:, 1]  # x_cam = y_world (right)\n",
    "    points_cam_remapped[:, 1] = -points_camera[:, 2]  # y_cam = -z_world (down)\n",
    "    points_cam_remapped[:, 2] = points_camera[:, 0]  # z_cam = x_world (forward)\n",
    "\n",
    "    # Camera intrinsics\n",
    "    fov_rad = np.radians(camera_fov)\n",
    "    focal_length_y = camera_height / (2 * np.tan(fov_rad / 2))\n",
    "    aspect_ratio = camera_width / camera_height\n",
    "    focal_length_x = focal_length_y * aspect_ratio\n",
    "    cx = camera_width / 2\n",
    "    cy = camera_height / 2\n",
    "\n",
    "    # Project to image\n",
    "    projected = []\n",
    "    for i in range(len(points_cam_remapped)):\n",
    "        z = points_cam_remapped[i, 2]\n",
    "        if z > 1e-6:  # Point in front of camera\n",
    "            x_img = (points_cam_remapped[i, 0] * focal_length_x / z) + cx\n",
    "            y_img = (points_cam_remapped[i, 1] * focal_length_y / z) + cy\n",
    "            inside = 0 <= x_img < camera_width and 0 <= y_img < camera_height\n",
    "            projected.append(((x_img, y_img), inside))\n",
    "        else:\n",
    "            projected.append(((0, 0), False))\n",
    "\n",
    "    return projected\n",
    "\n",
    "\n",
    "def draw_route_and_waypoints_with_config(image, pred_route, pred_waypoints, camera_config, route_color):\n",
    "    \"\"\"\n",
    "    Draw predicted route (blue), waypoints (red), and dense path (small red dots) on an image using specific camera config.\n",
    "\n",
    "    Args:\n",
    "        image: BGR image to draw on\n",
    "        pred_route: Predicted route tensor (N, 2) in vehicle coordinates\n",
    "        pred_waypoints: Predicted waypoints tensor (N, 2) in vehicle coordinates\n",
    "        camera_config: Dictionary with camera parameters (x, y, z, pitch, yaw, fov)\n",
    "\n",
    "    Returns:\n",
    "        Image with route and waypoints drawn\n",
    "    \"\"\"\n",
    "    route_color = (0, 255, 255) if route_color is None else route_color\n",
    "    img_with_viz = image.copy()\n",
    "    camera_height = image.shape[0]\n",
    "    camera_width = image.shape[1]\n",
    "\n",
    "    # Extract camera parameters from config\n",
    "    camera_fov = float(camera_config[\"fov\"])\n",
    "    camera_pos = [camera_config[\"x\"], camera_config[\"y\"], camera_config[\"z\"]]\n",
    "    camera_rot = [0, camera_config[\"pitch\"], camera_config[\"yaw\"]]  # roll, pitch, yaw\n",
    "\n",
    "    # Draw route in blue\n",
    "    if pred_waypoints is not None and len(pred_waypoints) > 0:\n",
    "        route_points = pred_waypoints.detach().cpu().float().numpy()\n",
    "        projected_route = project_points_to_image(camera_rot, camera_pos, camera_fov, camera_width, camera_height, route_points)\n",
    "\n",
    "        # Draw circles for waypoints\n",
    "        for pt, inside in projected_route:\n",
    "            if inside:\n",
    "                cv2.circle(\n",
    "                    img_with_viz,\n",
    "                    (int(pt[0]), int(pt[1])),\n",
    "                    radius=3,\n",
    "                    color=route_color,\n",
    "                    thickness=-1,  # Red in BGR\n",
    "                    lineType=cv2.LINE_AA,\n",
    "                )\n",
    "        # Draw connected line for route\n",
    "        for i in range(len(projected_route) - 1):\n",
    "            pt1, inside1 = projected_route[i]\n",
    "            pt2, inside2 = projected_route[i + 1]\n",
    "            if inside1 and inside2:\n",
    "                cv2.line(\n",
    "                    img_with_viz,\n",
    "                    (int(pt1[0]), int(pt1[1])),\n",
    "                    (int(pt2[0]), int(pt2[1])),\n",
    "                    route_color,  # Blue in BGR\n",
    "                    thickness=2,\n",
    "                    lineType=cv2.LINE_AA,\n",
    "                )\n",
    "\n",
    "    return img_with_viz\n",
    "\n",
    "\n",
    "def draw_target_points_bev(image, target_points, camera_config, tp_color):\n",
    "    \"\"\"\n",
    "    Draw previous, current, and next target points on BEV camera image as squares.\n",
    "\n",
    "    Args:\n",
    "        image: BGR image to draw on\n",
    "        target_points: Dictionary with keys 'previous', 'current', 'next' containing (x, y) coordinates\n",
    "        camera_config: Dictionary with camera parameters (x, y, z, pitch, yaw, fov)\n",
    "\n",
    "    Returns:\n",
    "        Image with target points drawn\n",
    "    \"\"\"\n",
    "    img_with_targets = image.copy()\n",
    "    camera_height = image.shape[0]\n",
    "    camera_width = image.shape[1]\n",
    "\n",
    "    # Extract camera parameters from config\n",
    "    camera_fov = float(camera_config[\"fov\"])\n",
    "    camera_pos = [camera_config[\"x\"], camera_config[\"y\"], camera_config[\"z\"]]\n",
    "    camera_rot = [0, camera_config[\"pitch\"], camera_config[\"yaw\"]]\n",
    "\n",
    "    # Define colors and sizes for each target point (BGR format)\n",
    "    targets_config = [\n",
    "        # (\"previous\", (255, 0, 0), 9),  # Gray, smaller square\n",
    "        (\"current\", (255, 0, 0) if tp_color is None else tp_color, 9),  # Green, bigger square\n",
    "        # (\"next\", (255, 0, 0), 9),  # Cyan, smaller square\n",
    "    ]\n",
    "\n",
    "    for key, color, size in targets_config:\n",
    "        if key in target_points and target_points[key] is not None:\n",
    "            # Get target point in vehicle coordinates\n",
    "            target_point = np.array([[target_points[key][0], target_points[key][1]]])\n",
    "\n",
    "            # Project to image\n",
    "            projected = project_points_to_image(camera_rot, camera_pos, camera_fov, camera_width, camera_height, target_point)\n",
    "\n",
    "            if len(projected) > 0:\n",
    "                pt, inside = projected[0]\n",
    "                if inside:\n",
    "                    # Draw square (rectangle with equal width and height)\n",
    "                    x, y = int(pt[0]), int(pt[1])\n",
    "                    cv2.circle(\n",
    "                        img_with_targets,\n",
    "                        (x, y),\n",
    "                        size + 2,\n",
    "                        (255, 255, 255),\n",
    "                        thickness=-1,\n",
    "                        lineType=cv2.LINE_AA,\n",
    "                    )\n",
    "\n",
    "                    # Filled colored circle\n",
    "                    cv2.circle(\n",
    "                        img_with_targets,\n",
    "                        (x, y),\n",
    "                        size,\n",
    "                        color,\n",
    "                        thickness=-1,\n",
    "                        lineType=cv2.LINE_AA,\n",
    "                    )\n",
    "\n",
    "    return img_with_targets\n",
    "\n",
    "\n",
    "def draw(image, pred_route=None, pred_waypoints=None, pred_bboxes=None, target_points=None, color=None):\n",
    "    \"\"\"Save demo camera images with camera name labels and optional route/waypoint/bbox visualization.\"\"\"\n",
    "    camera_config = camera_calibration\n",
    "\n",
    "    # Start with the base image\n",
    "    processed_image = image.copy()\n",
    "\n",
    "    # Add route and waypoint visualization if enabled for this camera\n",
    "    processed_image = draw_route_and_waypoints_with_config(processed_image, pred_route, pred_waypoints, camera_config, color)\n",
    "\n",
    "    # Add target points visualization for BEV camera\n",
    "    processed_image = draw_target_points_bev(processed_image, target_points, camera_config, color)\n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "\n",
    "camera_image = cv2.imread(camera_path)\n",
    "camera_image = cv2.cvtColor(camera_image, cv2.COLOR_BGR2RGB)\n",
    "anchors = [-25, 0, 25]\n",
    "\n",
    "num = len(anchors) ** 2\n",
    "\n",
    "rainbow_colors = []\n",
    "for k in range(num):\n",
    "    r, g, b = colorsys.hsv_to_rgb(k / num, 0.9, 0.9)\n",
    "    rgb = (np.array([r, g, b]) * 255).astype(np.uint8)\n",
    "    rainbow_colors.append(tuple(int(x) for x in rgb))\n",
    "\n",
    "for i, (ax, ay) in enumerate(itertools.product(anchors, anchors)):\n",
    "    if ax == 0 and ay == 0:\n",
    "        continue\n",
    "    model_input[\"speed\"] = torch.Tensor([[15.0]]).to(model_input[\"target_point\"].device)\n",
    "    model_input[\"target_point\"] = torch.tensor([[ax, ay]], device=model_input[\"target_point\"].device)\n",
    "    model_prediction = open_loop_inference.forward(model_input)\n",
    "    target_points = {\n",
    "        \"previous\": model_input.get(\"target_point_previous\").cpu().numpy().squeeze(),\n",
    "        \"current\": model_input.get(\"target_point\").cpu().numpy().squeeze(),\n",
    "        \"next\": model_input.get(\"target_point_next\").cpu().numpy().squeeze(),\n",
    "    }\n",
    "    camera_image = draw(\n",
    "        camera_image,\n",
    "        model_prediction.pred_route[0],\n",
    "        model_prediction.pred_future_waypoints[0],\n",
    "        target_points=target_points,\n",
    "        color=rainbow_colors[i],\n",
    "    )\n",
    "plt.imshow(camera_image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(target_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_image_space(points_2d, camera_config, camera_width, camera_height):\n",
    "    \"\"\"\n",
    "    Convert 2D world coordinates to image space.\n",
    "\n",
    "    Args:\n",
    "        points_2d: numpy array of shape (N, 2) with (x, y) coordinates\n",
    "        camera_config: Dictionary with camera parameters\n",
    "        camera_width: Image width\n",
    "        camera_height: Image height\n",
    "\n",
    "    Returns:\n",
    "        List of (x, y) tuples in image space (or None if out of bounds)\n",
    "    \"\"\"\n",
    "    camera_fov = float(camera_config[\"fov\"])\n",
    "    camera_pos = [camera_config[\"x\"], camera_config[\"y\"], camera_config[\"z\"]]\n",
    "    camera_rot = [0, camera_config[\"pitch\"], camera_config[\"yaw\"]]\n",
    "\n",
    "    projected = project_points_to_image(camera_rot, camera_pos, camera_fov, camera_width, camera_height, points_2d)\n",
    "\n",
    "    result = []\n",
    "    for (x, y), inside in projected:\n",
    "        if inside:\n",
    "            result.append([float(x), float(y)])\n",
    "        else:\n",
    "            result.append(None)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_target_point_grid(x_range, y_range, step=1.0):\n",
    "    \"\"\"\n",
    "    Generate grid of target points.\n",
    "\n",
    "    Args:\n",
    "        x_range: (min, max) for x coordinate\n",
    "        y_range: (min, max) for y coordinate\n",
    "        step: Grid step size in meters\n",
    "\n",
    "    Returns:\n",
    "        List of (x, y) tuples\n",
    "    \"\"\"\n",
    "    x_values = np.arange(x_range[0], x_range[1] + step, step)\n",
    "    y_values = np.arange(y_range[0], y_range[1] + step, step)\n",
    "\n",
    "    grid_points = []\n",
    "    for x in x_values:\n",
    "        for y in y_values:\n",
    "            if x == 0 and y == 0:  # Skip origin\n",
    "                continue\n",
    "            grid_points.append([float(x), float(y)])\n",
    "\n",
    "    return grid_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate JSON data for interactive widget\n",
    "camera_height = camera_image.shape[0]\n",
    "camera_width = camera_image.shape[1]\n",
    "\n",
    "# Generate target point grid (1m spacing from -20m to 20m in both x and y)\n",
    "target_points_grid = generate_target_point_grid(x_range=(-20, 20), y_range=(-20, 20), step=1.0)\n",
    "\n",
    "print(f\"Generated {len(target_points_grid)} target points\")\n",
    "\n",
    "# Initialize result structure\n",
    "widget_data = {\"image_width\": camera_width, \"image_height\": camera_height, \"misaligned\": [], \"aligned\": []}\n",
    "\n",
    "# Process both models\n",
    "model_configs = [\n",
    "    {\n",
    "        \"checkpoint_dir\": \"outputs/training/700_regnety_032/010_postrain32_0/250913_153308\",\n",
    "        \"key\": \"misaligned\",\n",
    "        \"use_tfv5\": True,\n",
    "    },\n",
    "    {\n",
    "        \"checkpoint_dir\": \"outputs/training/733_scaled_regnety/012_postrain32_2/251025_182334\",\n",
    "        \"key\": \"aligned\",\n",
    "        \"use_tfv5\": False,\n",
    "    },\n",
    "]\n",
    "\n",
    "for model_config in model_configs:\n",
    "    checkpoint_dir = model_config[\"checkpoint_dir\"]\n",
    "    data_key = model_config[\"key\"]\n",
    "\n",
    "    print(f\"\\nProcessing {data_key} model...\")\n",
    "\n",
    "    # Load model\n",
    "    open_loop_config = OpenLoopConfig()\n",
    "    open_loop_config.strict_weight_load = False\n",
    "\n",
    "    with open(os.path.join(checkpoint_dir, \"config.json\"), encoding=\"utf-8\") as f:\n",
    "        json_config = json.loads(f.read())\n",
    "\n",
    "    training_config = TrainingConfig(json_config)\n",
    "    training_config.use_tfv5_planning_decoder = model_config[\"use_tfv5\"]\n",
    "\n",
    "    open_loop_inference = OpenLoopInference(\n",
    "        config_training=training_config,\n",
    "        config_open_loop=open_loop_config,\n",
    "        model_path=checkpoint_dir,\n",
    "        device=torch.device(\"cuda:0\"),\n",
    "        prefix=\"model\",\n",
    "    )\n",
    "\n",
    "    # Load input data\n",
    "    model_input = torch.load(input_path)\n",
    "\n",
    "    # Process each target point\n",
    "    for i, (tx, ty) in enumerate(target_points_grid):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"  Processing target point {i + 1}/{len(target_points_grid)}\")\n",
    "\n",
    "        # Set target point and speed\n",
    "        model_input[\"speed\"] = torch.Tensor([[10.0]]).to(model_input[\"target_point\"].device)\n",
    "        model_input[\"target_point\"] = torch.tensor([[tx, ty]], device=model_input[\"target_point\"].device)\n",
    "\n",
    "        # Run inference\n",
    "        model_prediction = open_loop_inference.forward(model_input)\n",
    "\n",
    "        # Convert target point to image space\n",
    "        target_point_world = np.array([[tx, ty]])\n",
    "        target_point_img = convert_to_image_space(target_point_world, camera_calibration, camera_width, camera_height)\n",
    "\n",
    "        # Convert predictions to image space\n",
    "        pred_waypoints = model_prediction.pred_future_waypoints[0].detach().cpu().float().numpy()\n",
    "        waypoints_img = convert_to_image_space(pred_waypoints, camera_calibration, camera_width, camera_height)\n",
    "\n",
    "        # Store data\n",
    "        data_entry = {\n",
    "            \"target_point_world\": [tx, ty],\n",
    "            \"target_point_image\": target_point_img[0] if target_point_img[0] is not None else None,\n",
    "            \"waypoints_image\": waypoints_img,\n",
    "        }\n",
    "\n",
    "        widget_data[data_key].append(data_entry)\n",
    "\n",
    "    print(f\"  Completed {data_key} model: {len(widget_data[data_key])} entries\")\n",
    "\n",
    "# Save to JSON\n",
    "output_json_path = os.path.join(input_root, \"widget_data.json\")\n",
    "with open(output_json_path, \"w\") as f:\n",
    "    json.dump(widget_data, f, indent=2)\n",
    "\n",
    "print(f\"\\nSaved widget data to: {output_json_path}\")\n",
    "print(f\"Total misaligned entries: {len(widget_data['misaligned'])}\")\n",
    "print(f\"Total aligned entries: {len(widget_data['aligned'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample to verify the data looks correct\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "for idx, (model_name, ax) in enumerate(zip([\"misaligned\", \"aligned\"], axes)):\n",
    "    # Show base image\n",
    "    ax.imshow(camera_image)\n",
    "    ax.set_title(f\"{model_name.capitalize()} Model - Sample Predictions\")\n",
    "\n",
    "    # Sample every 10th entry to avoid clutter\n",
    "    sample_indices = range(0, len(widget_data[model_name]), 10)\n",
    "\n",
    "    for i in sample_indices:\n",
    "        entry = widget_data[model_name][i]\n",
    "\n",
    "        # Draw target point\n",
    "        if entry[\"target_point_image\"] is not None:\n",
    "            tx, ty = entry[\"target_point_image\"]\n",
    "            ax.plot(tx, ty, \"ro\", markersize=8, markeredgecolor=\"white\", markeredgewidth=2)\n",
    "\n",
    "        # Draw waypoints\n",
    "        waypoints = [w for w in entry[\"waypoints_image\"] if w is not None]\n",
    "        if waypoints:\n",
    "            xs = [w[0] for w in waypoints]\n",
    "            ys = [w[1] for w in waypoints]\n",
    "            ax.plot(xs, ys, \"b-\", linewidth=2, alpha=0.6)\n",
    "\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nData structure preview:\")\n",
    "print(f\"Misaligned sample entry: {widget_data['misaligned'][0]}\")\n",
    "print(f\"\\nAligned sample entry: {widget_data['aligned'][0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lead",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
